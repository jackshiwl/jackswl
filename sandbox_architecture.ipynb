{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FxXFWBdssYCe",
        "SeIqvzIjsdNp",
        "tQjx6OKpQLd8"
      ],
      "authorship_tag": "ABX9TyMcRxzcWMnXvlSxAf/Z29GN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modules"
      ],
      "metadata": {
        "id": "FxXFWBdssYCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LgOdkgHFhz9"
      },
      "outputs": [],
      "source": [
        "# Modules\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.models import Model\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from keras.layers import add\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Softmax\n",
        "\n",
        "# part 2\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from numpy import save\n",
        "from numpy import load\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import xarray as xr\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code from Paper"
      ],
      "metadata": {
        "id": "SeIqvzIjsdNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual block\n",
        "def res_block_gen(model, kernal_size, filters, strides, initializer):\n",
        "    \n",
        "    gen = model\n",
        "    \n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\", kernel_initializer=initializer)(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "    # Using Parametric ReLU\n",
        "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\", kernel_initializer=initializer)(model)\n",
        "    model = BatchNormalization(momentum = 0.5)(model)\n",
        "        \n",
        "    model = add([gen, model])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "\n",
        "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
        "class Generator(object):\n",
        "\n",
        "    def __init__(self, noise_shape):\n",
        "        \n",
        "        self.noise_shape = noise_shape\n",
        "\n",
        "    def generator(self):\n",
        "        init = RandomNormal(stddev=0.02)\n",
        "        \n",
        "        gen_input = Input(shape = self.noise_shape)\n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(gen_input)\n",
        "        model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
        "\t    \n",
        "        gen_model = model\n",
        "        \n",
        "        # Using 16 Residual Blocks\n",
        "        for index in range(16):\n",
        "\t        model = res_block_gen(model, 3, 64, 1, init)\n",
        "            \n",
        "\t    \n",
        "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n",
        "        model = BatchNormalization(momentum = 0.5)(model)\n",
        "        model = add([gen_model, model])\n",
        "\t    \n",
        "        model = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n",
        "        \n",
        "        # Task1 for downscaling to reanalysis (same task 2 at the moment)\n",
        "        model1 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n",
        "        model1 = UpSampling2D(size = 3)(model1)\n",
        "        model1 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model1)\n",
        "        \n",
        "        model1 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model1)\n",
        "        model1 = UpSampling2D(size = 3)(model1)\n",
        "        model1 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model1)\n",
        "    \n",
        "        model1 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model1)\n",
        "        model1 = UpSampling2D(size = 5)(model1)\n",
        "        model1 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model1)\n",
        "\t    \n",
        "        output1 = Conv2D(filters = 1, kernel_size = 9, strides = 1, padding = \"same\", kernel_initializer=init)(model1)\n",
        "        \n",
        "        # Task2 for downscaling to WRF\n",
        "        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n",
        "        model2 = UpSampling2D(size = 3)(model2)\n",
        "        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n",
        "        \n",
        "        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n",
        "        model2 = UpSampling2D(size = 3)(model2)\n",
        "        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n",
        "    \n",
        "        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n",
        "        model2 = UpSampling2D(size = 5)(model2)\n",
        "        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n",
        "\t    \n",
        "        output2 = Conv2D(filters = 1, kernel_size = 9, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n",
        "\t   \n",
        "        generator_model = Model(inputs = gen_input, outputs = [output1, output2]) # reanalysis, WRF\n",
        "        \n",
        "        return generator_model"
      ],
      "metadata": {
        "id": "WVTDQOTxsFa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss functions"
      ],
      "metadata": {
        "id": "tQjx6OKpQLd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_MSE_weighted(y_true, y_pred):\n",
        "  weights= tf.clip_by_value(y_true, K.log(0.1+1), K.log(100.0+1))\n",
        "  return K.mean(tf.multiply(weights, tf.abs(tf.subtract(y_pred, y_true))))\n",
        "\n",
        "def make_FSS_loss(mask_size):  # choose any mask size for calculating densities\n",
        "\n",
        "    def my_FSS_loss(y_true, y_pred):\n",
        "\n",
        "        # First: DISCRETIZE y_true and y_pred to have only binary values 0/1 \n",
        "        # (or close to those for soft discretization)\n",
        "        want_hard_discretization = False\n",
        "\n",
        "        # This example assumes that y_true, y_pred have the shape (None, N, N, 1).\n",
        "        \n",
        "        cutoff = 0.5  # choose the cut off value for discretization\n",
        "\n",
        "        if (want_hard_discretization):\n",
        "           # Hard discretization:\n",
        "           # can use that in metric, but not in loss\n",
        "           y_true_binary = tf.where(y_true>cutoff, 1.0, 0.0)\n",
        "           y_pred_binary = tf.where(y_pred>cutoff, 1.0, 0.0)\n",
        "\n",
        "        else:\n",
        "           # Soft discretization\n",
        "           c = 10 # make sigmoid function steep\n",
        "           y_true_binary = tf.math.sigmoid( c * ( y_true - cutoff ))\n",
        "           y_pred_binary = tf.math.sigmoid( c * ( y_pred - cutoff ))\n",
        "\n",
        "        # Done with discretization.\n",
        "\n",
        "        # To calculate densities: apply average pooling to y_true.\n",
        "        # Result is O(mask_size)(i,j) in Eq. (2) of [RL08].\n",
        "        # Since we use AveragePooling, this automatically includes the factor 1/n^2 in Eq. (2).\n",
        "        pool1 = tf.keras.layers.AveragePooling2D(pool_size=(mask_size, mask_size), strides=(1, 1), \n",
        "           padding='valid')\n",
        "        y_true_density = pool1(y_true_binary);\n",
        "        # Need to know for normalization later how many pixels there are after pooling\n",
        "        n_density_pixels = tf.cast( (tf.shape(y_true_density)[1] * tf.shape(y_true_density)[2]) , \n",
        "           tf.float32 )\n",
        "\n",
        "        # To calculate densities: apply average pooling to y_pred.\n",
        "        # Result is M(mask_size)(i,j) in Eq. (3) of [RL08].\n",
        "        # Since we use AveragePooling, this automatically includes the factor 1/n^2 in Eq. (3).\n",
        "        pool2 = tf.keras.layers.AveragePooling2D(pool_size=(mask_size, mask_size),\n",
        "                                                 strides=(1, 1), padding='valid')\n",
        "        y_pred_density = pool2(y_pred_binary);\n",
        "\n",
        "        # This calculates MSE(n) in Eq. (5) of [RL08].\n",
        "        # Since we use MSE function, this automatically includes the factor 1/(Nx*Ny) in Eq. (5).\n",
        "        MSE_n = tf.keras.losses.MeanSquaredError()(y_true_density, y_pred_density)\n",
        "\n",
        "        # To calculate MSE_n_ref in Eq. (7) of [RL08] efficiently:\n",
        "        # multiply each image with itself to get square terms, then sum up those terms.\n",
        "\n",
        "        # Part 1 - calculate sum( O(n)i,j^2\n",
        "        # Take y_true_densities as image and multiply image by itself.\n",
        "        O_n_squared_image = tf.keras.layers.Multiply()([y_true_density, y_true_density])\n",
        "        # Flatten result, to make it easier to sum over it.\n",
        "        O_n_squared_vector = tf.keras.layers.Flatten()(O_n_squared_image)\n",
        "        # Calculate sum over all terms.\n",
        "        O_n_squared_sum = tf.reduce_sum(O_n_squared_vector)\n",
        "\n",
        "        # Same for y_pred densitites:\n",
        "        # Multiply image by itself\n",
        "        M_n_squared_image = tf.keras.layers.Multiply()([y_pred_density, y_pred_density])\n",
        "        # Flatten result, to make it easier to sum over it.\n",
        "        M_n_squared_vector = tf.keras.layers.Flatten()(M_n_squared_image)\n",
        "        # Calculate sum over all terms.\n",
        "        M_n_squared_sum = tf.reduce_sum(M_n_squared_vector)\n",
        "    \n",
        "        MSE_n_ref = (O_n_squared_sum + M_n_squared_sum) / n_density_pixels\n",
        "        \n",
        "        # FSS score according to Eq. (6) of [RL08].\n",
        "        # FSS = 1 - (MSE_n / MSE_n_ref)\n",
        "\n",
        "        # FSS is a number between 0 and 1, with maximum of 1 (optimal value).\n",
        "        # In loss functions: We want to MAXIMIZE FSS (best value is 1), \n",
        "        # so return only the last term to minimize.\n",
        "\n",
        "        # Avoid division by zero if MSE_n_ref == 0\n",
        "        # MSE_n_ref = 0 only if both input images contain only zeros.\n",
        "        # In that case both images match exactly, i.e. we should return 0.\n",
        "        my_epsilon = tf.keras.backend.epsilon()  # this is 10^(-7)\n",
        "\n",
        "        if (want_hard_discretization):\n",
        "           if MSE_n_ref == 0:\n",
        "              return( MSE_n )\n",
        "           else:\n",
        "              return( MSE_n / MSE_n_ref )\n",
        "        else:\n",
        "           return (MSE_n / (MSE_n_ref + my_epsilon) )\n",
        "\n",
        "    return my_FSS_loss \n",
        "\n",
        "mask_size = 6 "
      ],
      "metadata": {
        "id": "Blj0tsfb-zt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Architecture"
      ],
      "metadata": {
        "id": "evj2LKTaTGQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape_hr = (90, 135, 1)\n",
        "image_shape_lr = (2, 3, 1)\n",
        "downscale_factor = 45"
      ],
      "metadata": {
        "id": "kK3dlslu-2Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load low resolution REFORECAST data for training\n",
        "reforecast_train = tf.random.normal((100, 2, 3, 1)).numpy() # 13 , 16\n",
        "\n",
        "# load high resolution REANALYSIS data for training\n",
        "reanalysis_train = tf.random.normal((100, 90, 135, 1)).numpy()  # 156, 192\n",
        "\n",
        "#load low resolution REFORECAST data for validation\n",
        "reforecast_val = tf.random.normal((10, 2, 3, 1)).numpy() \n",
        "\n",
        "#load high resolution REANALYSIS data for validation\n",
        "reanalysis_val = tf.random.normal((10, 90, 135, 1)).numpy() \n",
        "\n",
        "#load high resolution WRF data for training\n",
        "WRF_train = tf.random.normal((100, 90, 135, 1)).numpy() \n",
        "\n",
        "#load high resolution WRF data for validation\n",
        "WRF_val = tf.random.normal((10, 90, 135, 1)).numpy() "
      ],
      "metadata": {
        "id": "lfVGm2t4-5AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 64\n",
        "# len(np.random.randint(0, merra2_train.shape[0], size=batch_size))\n",
        "# merra2_train[np.random.randint(0, merra2_train.shape[0], size=64)].shape"
      ],
      "metadata": {
        "id": "_1_jge3xHm9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size):\n",
        "    \n",
        "    x_train_lr = reforecast_train             # reforecast lr\n",
        "    y_train_hr = reanalysis_train             # reanalysis hr\n",
        "    \n",
        "    x_val_lr = reforecast_val                 # reforecast lr val\n",
        "    y_val_hr = reanalysis_val                 # reanalysis hr val\n",
        "    \n",
        "    x_train_lr = reforecast_train             # reforecast lr\n",
        "    y_train_WRF = WRF_train                   # WRF hr\n",
        "    y_train_hr = reanalysis_train             # reanalysis\n",
        "    \n",
        "    x_val_lr = reforecast_val                 # reforecast\n",
        "    y_val_WRF = WRF_val                       # WRF hr val\n",
        "    y_val_hr = reanalysis_val                 # reanalysis\n",
        "    \n",
        " #   loss=MSE_LOSS(image_shape_hr)\n",
        "    \n",
        "    batch_count = int(x_train_lr.shape[0] / batch_size)\n",
        "    \n",
        "    generator = Generator(image_shape_lr).generator()\n",
        "    generator.compile(loss=[make_FSS_loss(mask_size), my_MSE_weighted], optimizer = Adam(learning_rate=0.0001, beta_1=0.9), loss_weights=[0.01, 1.0],metrics=['mae', 'mse'])\n",
        "    loss_file = open('losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "        \n",
        "    for e in range(1, epochs+1):\n",
        "        \n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        \n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_lr.shape[0], size=batch_size)\n",
        "            \n",
        "            x_lr = x_train_lr[rand_nums]   # reforecast lr\n",
        "            y_hr = y_train_hr[rand_nums]   # reanalysis hr\n",
        "            y_WRF = y_train_WRF[rand_nums] # WRF hr\n",
        "\n",
        "            gen_loss = generator.train_on_batch(x_lr, [y_WRF,y_hr])\n",
        "\n",
        "        gen_loss = str(gen_loss)\n",
        "        val_loss = generator.evaluate(x_val_lr, [y_val_WRF, y_val_hr], verbose=0)\n",
        "        val_loss = str(val_loss)\n",
        "        loss_file = open('losses.txt' , 'a') \n",
        "        loss_file.write('epoch%d : generator_loss = %s; validation_loss = %s\\n' \n",
        "                        %(e, gen_loss, val_loss))\n",
        "        \n",
        "        loss_file.close()\n",
        "        # if e <=20:\n",
        "        #     if e  % 5== 0:\n",
        "        #         generator.save('gen_model%d.h5' % e)\n",
        "        # else:\n",
        "        #      if e  % 10 == 0:\n",
        "        #         generator.save('gen_model%d.h5' % e)\n",
        "        \n",
        "\n",
        "\n",
        "train(1, 3)"
      ],
      "metadata": {
        "id": "qdqz1BJO-7EZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}